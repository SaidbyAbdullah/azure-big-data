{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74ea95b-af67-4d77-89b5-75397189dc04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import necessary libaries\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb0ea593-44d7-4355-bca8-6ddcad838b59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"ML Model\")\n",
    "         .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22e2602c-df6f-4605-a60e-40d8a380ba3e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####Load the ML model and the stringIdexer generated, and also the Posts file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae326c25-f343-465f-aca1-efa1f05d0eae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "posts = spark.read.parquet(\"/mnt/adls_test/Posts/*\")\n",
    "ml_model = \"/mnt/adls_test/model\"\n",
    "stringindexer = \"/mnt/adls_test/stringindexer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a27b6539-2e7e-4029-927c-e4c40de91ffb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Create a User Defined Function to filter and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "607d5702-b922-4dce-9d72-21eb03ed8c3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# User defined function\n",
    "def predictions_udf(df, ml_model, stringindexer):\n",
    "    from pyspark.sql.functions import col, regexp_replace, lower, trim\n",
    "    from pyspark.ml import PipelineModel\n",
    "\n",
    "    # Filter out empty body text\n",
    "    df = df.filter(\"Body is not null\")\n",
    "    # Making sure the naming of the columns are consistent with the model\n",
    "    df = df.select(col(\"Body\").alias(\"text\"), col(\"Tags\"))\n",
    "    # Preprocessing of the feature column\n",
    "    cleaned = df.withColumn('text', regexp_replace('text', r\"http\\S+\", \"\")) \\\n",
    "                    .withColumn('text', regexp_replace('text', r\"[^a-zA-z]\", \" \")) \\\n",
    "                    .withColumn('text', regexp_replace('text', r\"\\s+\", \" \")) \\\n",
    "                    .withColumn('text', lower('text')) \\\n",
    "                    .withColumn('text', trim('text')) \n",
    "\n",
    "    # Load in the saved pipeline model\n",
    "    model = PipelineModel.load(ml_model)\n",
    "\n",
    "    # Making the prediction\n",
    "    prediction = model.transform(df)\n",
    "\n",
    "    predicted = prediction.select(col('text'), col('Tags'), col('prediction'))\n",
    "\n",
    "    # Decoding the indexer\n",
    "    from pyspark.ml.feature import StringIndexerModel, IndexToString\n",
    "\n",
    "    # Load in the StringIndexer that was saved\n",
    "    indexer = StringIndexerModel.load(stringindexer)\n",
    "\n",
    "    # Initialize the IndexToString converter\n",
    "    i2s = IndexToString(inputCol = 'prediction', outputCol = 'decoded', labels = indexer.labels)\n",
    "    converted = i2s.transform(predicted)\n",
    "\n",
    "    # Display the important columns\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce335921-121f-4d2c-a5a2-e8fdf746b01a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Run the UDF and generate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67ed3c3a-f49f-4e75-a1ac-8509e70531bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = predictions_udf(posts,ml_model, stringindexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09abf40b-49ba-495c-8d10-f5b18fb2c551",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Summarize which topics are the most popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcf7ed76-ea61-412b-9e60-3a7ec3690b0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# change the column name\n",
    "topics = result.withColumnRenamed('decoded', 'topic').select('topic')\n",
    "# Aggregate the topics and calculate the total qty of each topic\n",
    "topic_qty = topics.groupBy(col(\"topic\")).agg(count('topic').alias('qty')).orderBy(desc('qty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fa5a3cd-f3da-49c7-b09a-2fa4a6b86914",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n|               topic|qty|\n+--------------------+---+\n|agent-based-modeling|  4|\n|   memory-management|  1|\n|         multi-agent|  1|\n+--------------------+---+\n\n"
     ]
    }
   ],
   "source": [
    "topic_qty.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb54d84f-abfd-43a1-ba01-5cc3f3001607",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Save the result file to the BI folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2a0577e-7c97-4b65-b421-9b11a496444c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define this function\n",
    "def crt_sgl_file(result_path):\n",
    "# write the result to a folder container several files\n",
    "    path = \"/mnt/adls_test/BI/ml_result\"\n",
    "    topic_qty.write.option(\"delimiter\", \",\").option(\"header\", \"true\").mode(\"overwrite\").csv(path)\n",
    "# list the folder, find the csv file\n",
    "    filenames = dbutils.fs.ls(path)\n",
    "    name = ''\n",
    "    for filename in filenames:\n",
    "        if filename.name.endswith('csv'):\n",
    "            org_name = filename.name\n",
    "\n",
    "# copy the csv file to the path you want to save, in this example, we use \"/mnt/adls_test/BI/ml_result.csv\"\n",
    "    dbutils.fs.cp(path + '/'+ org_name, result_path)\n",
    "# delete the folder\n",
    "    dbutils.fs.rm(path, True)\n",
    "    print('single file created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "694325f1-8420-4c15-a5a4-6e3975bf4ac0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single file created\n"
     ]
    }
   ],
   "source": [
    "# run the function\n",
    "result_path = \"/mnt/adls_test/BI/ml_result.csv\"\n",
    "crt_sgl_file(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecd0fbe4-406a-4683-9fae-363429d480bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ML Sentiment Analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
